{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJGl2EaqRz16",
        "outputId": "1e65da0d-5a01-468f-8371-c44e790225d1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì¦ê°• ì´ë¯¸ì§€ ë³‘í•© ì™„ë£Œ: ['glioma', 'healthy', 'pituitary', 'meningioma']\n",
            "Found 34167 images belonging to 4 classes.\n",
            "Found 14640 images belonging to 4 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”µ [MLP ëª¨ë¸ í•™ìŠµ ì‹œì‘]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 715ms/step - accuracy: 0.4102 - loss: 4.9771 - val_accuracy: 0.3961 - val_loss: 1.2804 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 696ms/step - accuracy: 0.4920 - loss: 1.2096 - val_accuracy: 0.3805 - val_loss: 1.3632 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 701ms/step - accuracy: 0.5052 - loss: 1.1613 - val_accuracy: 0.3542 - val_loss: 1.3810 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 701ms/step - accuracy: 0.5147 - loss: 1.1422 - val_accuracy: 0.4171 - val_loss: 1.2360 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 692ms/step - accuracy: 0.5131 - loss: 1.1502 - val_accuracy: 0.3932 - val_loss: 1.3238 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 696ms/step - accuracy: 0.5278 - loss: 1.1306 - val_accuracy: 0.4001 - val_loss: 1.3071 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 699ms/step - accuracy: 0.5349 - loss: 1.1187 - val_accuracy: 0.4301 - val_loss: 1.2521 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.5339 - loss: 1.1163\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 700ms/step - accuracy: 0.5339 - loss: 1.1163 - val_accuracy: 0.4253 - val_loss: 1.2557 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 694ms/step - accuracy: 0.5577 - loss: 1.0839 - val_accuracy: 0.3959 - val_loss: 1.3452 - learning_rate: 5.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 700ms/step - accuracy: 0.5595 - loss: 1.0737 - val_accuracy: 0.4768 - val_loss: 1.1723 - learning_rate: 5.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 696ms/step - accuracy: 0.5647 - loss: 1.0673 - val_accuracy: 0.4456 - val_loss: 1.2304 - learning_rate: 5.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 687ms/step - accuracy: 0.5683 - loss: 1.0590 - val_accuracy: 0.4701 - val_loss: 1.2160 - learning_rate: 5.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 695ms/step - accuracy: 0.5574 - loss: 1.0727 - val_accuracy: 0.4466 - val_loss: 1.2270 - learning_rate: 5.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653ms/step - accuracy: 0.5621 - loss: 1.0584\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 691ms/step - accuracy: 0.5621 - loss: 1.0584 - val_accuracy: 0.4329 - val_loss: 1.2454 - learning_rate: 5.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 700ms/step - accuracy: 0.5681 - loss: 1.0437 - val_accuracy: 0.4342 - val_loss: 1.2543 - learning_rate: 2.5000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 689ms/step - accuracy: 0.5815 - loss: 1.0236 - val_accuracy: 0.4667 - val_loss: 1.1975 - learning_rate: 2.5000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 697ms/step - accuracy: 0.5757 - loss: 1.0259 - val_accuracy: 0.4721 - val_loss: 1.2058 - learning_rate: 2.5000e-04\n",
            "ğŸŸ£ [DNN ëª¨ë¸ í•™ìŠµ ì‹œì‘]\n",
            "Epoch 1/40\n",
            "\u001b[1m534/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 706ms/step - accuracy: 0.4006 - loss: 3.8808 - val_accuracy: 0.3652 - val_loss: 1.2917 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m243/534\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3:10\u001b[0m 655ms/step - accuracy: 0.4720 - loss: 1.2246"
          ]
        }
      ],
      "source": [
        "import zipfile, os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "aug_zip_dir = '/content/drive/MyDrive/ MyDrive BrainTumorDataset '\n",
        "raw_dataset_dir = '/content/BrainTumorRaw/multi_class_dataset'\n",
        "\n",
        "# ZIP ì••ì¶• í•´ì œ\n",
        "zip_map = {\n",
        "    'Glioma.zip': 'glioma',\n",
        "    'Meningioma.zip': 'meningioma',\n",
        "    'Pituitary.zip': 'pituitary',\n",
        "    'Healthy.zip': 'healthy'\n",
        "}\n",
        "for zip_file, class_name in zip_map.items():\n",
        "    zip_path = os.path.join(aug_zip_dir, zip_file)\n",
        "    target_dir = os.path.join(raw_dataset_dir, class_name)\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(target_dir)\n",
        "\n",
        "print(\"âœ… ì¦ê°• ì´ë¯¸ì§€ ë³‘í•© ì™„ë£Œ:\", os.listdir(raw_dataset_dir))\n",
        "\n",
        "# ë°ì´í„° ë¡œë”© ë° ì¦ê°•\n",
        "img_size = (224, 224)\n",
        "batch_size = 64\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
        "\n",
        "train_data = train_gen.flow_from_directory(\n",
        "    raw_dataset_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = val_gen.flow_from_directory(\n",
        "    raw_dataset_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "num_classes = len(train_data.class_indices)\n",
        "\n",
        "# âœ… ì½œë°± ì„¤ì •\n",
        "earlystop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=7,  # ë„‰ë„‰íˆ\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.keras',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,  # 4ë²ˆ ì—°ì† ê°œì„  ì—†ì„ ë•Œë§Œ ê°ì†Œ\n",
        "    min_lr=1e-7,  # ë„ˆë¬´ ì‘ì•„ì§€ëŠ” ê²ƒ ë°©ì§€\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# MLP ëª¨ë¸ ì •ì˜\n",
        "mlp_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=img_size + (3,)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "mlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"ğŸ”µ [MLP ëª¨ë¸ í•™ìŠµ ì‹œì‘]\")\n",
        "history_mlp = mlp_model.fit(\n",
        "    train_data,\n",
        "    epochs=40,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[earlystop, checkpoint, reduce_lr]\n",
        ")\n",
        "\n",
        "# DNN ëª¨ë¸ ì •ì˜\n",
        "dnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=img_size + (3,)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"ğŸŸ£ [DNN ëª¨ë¸ í•™ìŠµ ì‹œì‘]\")\n",
        "history_dnn = dnn_model.fit(\n",
        "    train_data,\n",
        "    epochs=40,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[earlystop, checkpoint, reduce_lr]\n",
        ")\n",
        "\n",
        "# ì •í™•ë„ ì‹œê°í™”\n",
        "def plot_history(history, title):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    plt.plot(acc, label='Train Accuracy')\n",
        "    plt.plot(val_acc, label='Val Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_mlp, \"MLP ì •í™•ë„\")\n",
        "plot_history(history_dnn, \"DNN ì •í™•ë„\")\n",
        "\n",
        "print(\"âœ… MLP ìµœì¢… ê²€ì¦ ì •í™•ë„:\", mlp_model.evaluate(val_data, verbose=0)[1])\n",
        "print(\"âœ… DNN ìµœì¢… ê²€ì¦ ì •í™•ë„:\", dnn_model.evaluate(val_data, verbose=0)[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSOLEY9PUXBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}