{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhVyyujST9FS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "input_height = 128\n",
        "input_width = 128\n",
        "input_channels = 1   # 흑백 이미지\n",
        "num_classes = 4\n",
        "\n",
        "# 데이터 디렉토리 경로\n",
        "data_dir = '/content/BrainMRI'\n",
        "assert os.path.exists(data_dir), \"데이터 폴더가 존재하지 않습니다.\"\n",
        "\n",
        "\n",
        "# 1. 데이터 증강 및 로딩\n",
        "\n",
        "\n",
        "# ImageDataGenerator: 학습용은 증강 포함, 검증용은 증강 제외 및 정규화만\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,                   # 0~1 정규화\n",
        "    rotation_range=30,                # -30 ~ +30도 회전\n",
        "    zoom_range=0.2,                  # 80%~120% 확대/축소\n",
        "    width_shift_range=0.2,           # 좌우 20% 이동\n",
        "    height_shift_range=0.2,          # 상하 20% 이동\n",
        "    horizontal_flip=True,            # 좌우 반전\n",
        "    validation_split=0.3             # 30%는 검증용으로 분리\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "# 학습용 데이터 생성기\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(input_height, input_width),\n",
        "    color_mode='grayscale',     # 흑백\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',   # 다중 클래스 분류용 one-hot 인코딩\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 검증용 데이터 생성기\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(input_height, input_width),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# 2. 모델 구성 (GRU)\n",
        "\n",
        "\n",
        "# GRU 입력은 (batch, timesteps=128, features=128)\n",
        "# 이미지 (128,128,1) → (128,128)로 reshape하여 시퀀스처럼 처리\n",
        "\n",
        "inputs = layers.Input(shape=(input_height, input_width, input_channels))\n",
        "\n",
        "# 흑백 채널 제거 후 시퀀스 형태로 변환\n",
        "x = layers.Reshape((input_height, input_width))(inputs)  # (batch, 128, 128)\n",
        "\n",
        "# GRU 레이어 3층 쌓기 (마지막 레이어는 return_sequences=False)\n",
        "x = layers.GRU(256, return_sequences=True)(x)\n",
        "x = layers.GRU(256, return_sequences=True)(x)\n",
        "x = layers.GRU(256)(x)  # 마지막 타임스텝 출력만 사용\n",
        "\n",
        "# 출력층: 클래스 수만큼 노드, softmax 활성화 함수\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 3. 콜백 정의\n",
        "\n",
        "\n",
        "earlystop = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(\n",
        "    'best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',          # 검증 손실 기준 학습률 감소\n",
        "    factor=0.5,                 # 학습률 50% 감소\n",
        "    patience=2,                 # 2회 연속 개선 없으면 감소\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# 4. 모델 학습\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[earlystop, checkpoint, reduce_lr]\n",
        ")\n",
        "\n",
        "# 5. 학습 결과 시각화\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# 손실 그래프\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss over epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Accuracy over epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ]
}